< } Preliminaries</h1>
<div class="definition" id="definition-majorant" >
    <div class="title">Majorant</div>
    <div class="content">
        An element \( x \) is called a <b>majorant</b> for a subset \( Y  \) of \( X \) if \( y \le x \) for every \( y \in Y \) 
    </div>
</div>
<div class="definition" id="definition-filtering-upward" >
    <div class="title">Filtering Upward</div>
    <div class="content">
        We say that an order is filtering upward if every pair in \( X \) (and hence every finite subset of \( X \) ) has a <a class="knowledge-link" href="/analysis/linear_operators.html#definition-majorant">majorant</a>.
    </div>
</div>
<div class="definition" id="definition-net" >
    <div class="title">Net</div>
    <div class="content">
        A net is a space \( X \) is a pair \( \left( A, i \right)  \) where \( A \) is an upward-filtering ordered set and \( i \) is a map from \( A \to X \)
    </div>
</div>
<div class="theorem" id="theorem-if-a-cauchy-sequence-has-a-convergent-subsequence-then-the-original-converges-there">
<div class="title">If a Cauchy Sequence has a Convergent Subsequence, then the Original Converges There</div>
<div class="content">
        Let \( X, d \) be a metric space, then if \( \left( x _ n \right) : \mathbb{ N } _ 1 \to X \) is cauchy, and there exists a <a class="knowledge-link" href="/fundamentals/sequences.html#definition-subsequence">subsequence</a> \( \left( x _ { \sigma \left( n \right) }   \right)  \) that converges to \( x \) then \( \left( x _ n \right) \to x  \)  as well.
          </div>
<div class="proof">
        Since \( \left( x _ { \sigma \left( n \right) } \right) \to x \) then given \( \epsilon \in \mathbb{ R } ^ +  \) we have some \( K \) such that for any \( k \ge K \) we have \( d \left( x _ { \sigma \left( k \right) } , x  \right) \lt \frac{\epsilon}{2}   \) since \( \left( x _ n \right)  \) is assumed cauchy then we obtain some \( N ^ \prime  \) such that for all \( n, m \ge N ^ \prime  \) we know that \( d \left( x _ n, x _ m \right) \lt \frac{\epsilon }{2} \), take \( N = N ^ \prime  \)  and let \( n \ge N \) since \( \sigma  \) is strictly increasing then there is some \( i \in \mathbb{ N } _ 1 \) such that \( \sigma \left( i \right) \ge N  \) let \( j := \max \left( i, K  \right)  \) thus we have
        \[
            d \left( x _ n, x \right) \le d \left( x _ n , x _ { \sigma \left( i \right) }   \right) + d \left( x _ { \sigma \left( i \right)  }, x   \right) \lt \frac{\epsilon }{2} + \frac{\epsilon }{2} = \epsilon
        \]
        as needed.
      </div>
</div>
<h1>Normed Spaces</h1>
<p>
    A bilinear form is a generlization of the idea of the dot product:
</p>
<div class="definition" id="definition-bilinear-form" >
    <div class="title">Bilinear Form</div>
    <div class="content">
        A bilinear form on a <a class="knowledge-link" href="/algebra/linear/vector_spaces/vector_spaces.html#definition-vector-space-over-a-field">vector space \(V\) over a field \(\mathbb{F}\)</a>  is a map \( H: V \times V \rightarrow \mathbb{F} \) such that
        <ol>
            <li>\(H\left(v_1+v_2, w\right)=H\left(v_1, w\right)+H\left(v_2, w\right)\), for all \(v_1, v_2, w \in V\)</li>
            <li>\(H\left(v, w_1+w_2\right)=H\left(v, w_1\right)+H\left(v, w_2\right)\), for all \(v, w_1, w_2 \in V\)</li>
            <li>\(H(a v, w)=a H(v, w)\), for all \(v, w \in V, a \in \mathbb{F}\)</li>
            <li>\(H(v, a w)=a H(v, w)\), for all \(v, w \in V, a \in \mathbb{F}\)</li>
        </ol>

    </div>
</div>
<ul>
    <li> A bilinear form \(H\) is called symmetric if \(H(v, w)=H(w, v)\) for all \(v, w \in V\). </li>
    <li> A bilinear form \(H\) is called skew-symmetric if \(H(v, w)=-H(w, v)\) for all \(v, w \in V\). </li>
    <li> A bilinear form \(H\) is called non-degenerate if for all \(v \in V\), there exists \(w \in V\), such that \(H(w, v) \neq 0\). </li>
    <li> A bilinear form \(H\) defines a map \(H^{\#}: V \rightarrow V^*\) which takes \(w\) to the linear map \(v \mapsto H(v, w)\). In other words, \(H^{\#}(w)(v)=H(v, w)\). </li>
</ul>
Note that \(H\) is non-degenerate if and only if the map \(H^{\#}: V \rightarrow V^*\) is injective. Since \(V\) and \(V^*\) are finite-dimensional vector spaces of the same dimension, this map is injective if and only if it is invertible.
<div class="definition" id="definition-sesquilinear-form" >
    <div class="title">Sesquilinear Form</div>
    <div class="content">
        Let \( \mathbb{ F }  \)  be a subfield of \( \mathbb{ C }  \) and \( U \)  and \( V \)  be <a class="knowledge-link" href="/algebra/linear/vector_spaces/vector_spaces.html#definition-vector-space-over-a-field">vector spaces</a>over \( \mathbb{ F }  \), then a <b>sesquilinear form</b> is a function \( u: U \times V \to \mathbb{ C } \) such that \( \forall \alpha \in \mathbb{ F } , x_1, x_2 \in U, y \in V \) we have:
        <ol>
            <li>
                 \( u \left(\alpha x_1 + x_2, y  \right) = \alpha  u \left( x_1, y \right)  + u \left( x_2, y \right)  \) 
            </li>
            <li>
                \( u \left( x, \alpha y_1 + y_2 \right) = \bar \alpha  u \left( x, y_1 \right)  + u \left( x, y _ 2 \right)  \) 
            </li>
        </ol>
    </div>
</div>
<p>
    Note that if \( \mathbb{ F }  \)  is a subfield of \( \mathbb{ R }  \) , then a sesquilinear form is a bilinear form.
</p>
<div class="definition" id="definition-isomorphism-between-hilbert-spaces" >
    <div class="title">Isomorphism Between Hilbert Spaces</div>
    <div class="content">
        Suppose that \( \mathcal{ H }  \) and \( \mathcal{ K }  \) are <a class="knowledge-link" href="/analysis/linear_operators.html#definition-hilbert-space">hilbert spaces</a> then an isomorphism between them is a surjective linear operator \( U : \mathcal{ H } \to \mathcal{ K }   \) such that 
        \[
         \left\langle Uh, Uk \right\rangle _ \mathcal{ K } = \left\langle h, k \right\rangle _ \mathcal{ H } 
        \] 
    </div>
</div>
<div class="definition" id="definition-isometry" >
    <div class="title">Isometry</div>
    <div class="content">
        A linear operator \( T : V \to W \) is an <b>isometry</b> if for all vectors \( v_1, v_2 \in V \) we have that 
        \[
          \left\lVert T \left( v _ 1 \right) - T \left( v _ 2 \right)   \right\rVert _ W = \left\lVert v_1 - v_2 \right\rVert _V
        \] 
    </div>
</div>
<div class="definition" id="definition-unitary-operator" >
    <div class="title">Unitary Operator</div>
    <div class="content">
        We say that a linear operator \( U : \mathcal{ H } \to \mathcal{ K }    \) between hilbert spaces is <b>unitary</b> whenever 
        \[
          U ^ * U = \operatorname{ id } _ \mathcal{ H }   \qquad \text{ and } \qquad U U ^ * = \operatorname{ id } _ \mathcal{ K } 
        \] 
    </div>
</div>
<div class="definition" id="definition-bounded-linear-operators-on-a-hilbert-space" >
    <div class="title">Bounded Linear Operators on a Hilbert Space</div>
    <div class="content">
        Suppose that \( \mathcal{ H }  \) is a hilbert space then we use the notation \( B \left( \mathcal{ H }  \right)  \) to denote all <a class="knowledge-link" href="/analysis/linear_operators.html#definition-bounded-linear-operator">bounded linear operators</a>
    </div>
</div>
<h1>week 3</h1>
<div class="proposition" id="proposition-unitary-operator-equivalences" >
    <div class="title">Unitary Operator Equivalences</div>
    <div class="content">
        Suppose that \( U : \mathcal{ H } \to \mathcal{ K }   \) is a bounded linear operator between <a class="knowledge-link" href="/analysis/linear_operators.html#definition-hilbert-space">hilbert spaces</a>, then the following are equivalent:
        <ol>
            <li>\( U \) is a <a class="knowledge-link" href="/analysis/linear_operators.html#definition-unitary-operator">unitary operator</a></li>
            <li>\( U \) is a surjective and \( \left\langle U h, U k \right\rangle _ \mathcal{ K } = \left\langle h, k \right\rangle _ \mathcal{ H }     \) </li>
            <li>\( U \) is a surjective isometry</li>
        </ol>
    </div>
    <div class="proof">
        <p>
            Let's prove that \( 1 \implies 2 \) so suppose that \( U \) is unitary, so then we know that \( U U ^ * = \operatorname{ id } _ \mathcal{ K }   \) which helps show that \( U \) is  surjective as given any \( k \in \mathcal{ K }  \) then we know that \( U \left( U ^ * k \right) = k  \), but then additionally we know that \( U ^ * U = \operatorname{ id } \mathcal{ H }   \) so that then we note that \( \left\langle Ux, Uy \right\rangle = \left\langle x, U ^ *, U \right\rangle = \left\langle x, y \right\rangle \) as needed.
        </p>
        <p>
            Now we prove that \( 2 \implies 3 \), but all we have to do is consider any \( h \in \mathcal{ H }  \) and thus we have that 
            \[ 
                \left\lVert U h \right\rVert ^ 2 =  \left\langle U h, U h \right\rangle _ \mathcal{ K } = \left\langle h , h \right\rangle _ \mathcal{ H } = \left\lVert h \right\rVert ^ 2
            \]
            and thus since the norm is non-negative then we can undo the square to obtain that \( \left\lVert U h \right\rVert _ \mathcal{ K } = \left\lVert h \right\rVert _ \mathcal{ H }     \) as needed.
        </p>
        <p>
            Now we finish \( 3 \implies 1 \), we note that \( \left\langle U ^ * U x, x \right\rangle = \left\langle Ux, Ux \right\rangle   \) as the adjoint is an involution, but then \( \left\langle Ux, Ux \right\rangle = \left\lVert U x \right\rVert ^ 2 = \left\lVert x \right\rVert ^ 2  = \left\langle x, x \right\rangle  \), thus we've shown that \( \left\langle U ^ * U x, x \right\rangle = \left\langle x, x \right\rangle   \) so we conclude that \( U ^ * U = I \) which shows that \( U \) is an invertible linear isometry with \( U ^ { -1 } = U ^ * \), in otherwords \( U \) is unitary.
        </p>
    </div>
</div>
<div class="definition" id="definition-unilateral-shift-operator" >
    <div class="title">Unilateral Shift Operator</div>
    <div class="content">
        Let \( H = \ell ^ 2 \left( \mathbb{ N }  \right)  \) then we define the <b>unilateral shift operator</b> as \( S : H \to H \) given by
        \[
          S \left( x _ 1, x_2, x_3, x_4, \ldots  \right) = \left( 0, x _ 1, x_2, x_3, \ldots  \right) 
        \] 
    </div>
</div>
<div class="proposition" id="proposition-the-unilateral-shift-is-an-isometry" >
    <div class="title">The Unilateral Shift Is an Isometry</div>
    <div class="content">
        As per title.
    </div>

    <div class="proof">
        Consider the following
        \[
        \begin{align*}
        \left\lVert S \left( x \right)  \right\rVert &= \sqrt{ \sum _ { n = 1 } ^ \infty \left\lvert \left( S x \right) _ n  \right\rvert ^ 2  } \\
        &= \sqrt{ \sum _ { n = 2 } ^ \infty 0 + \left\lvert x _ { n - 1 }  \right\rvert ^ 2  } \\
        &= \sqrt{ \sum _ { n = 1 } ^ \infty  \left\lvert x _ { n }  \right\rvert ^ 2  } \\
        &= \left\lVert x \right\rVert 
        \end{align*}
        \] 
    </div>
</div>
<div class="proposition" id="proposition-the-unilateral-shift-is-not-unitary" >
    <div class="title">The Unilateral Shift Is Not Unitary</div>
    <div class="content">
        As per title.
    </div>
    <div class="proof">
        We show it's not unitary by showing that it is not surjective, which is the case as the element \( \left( 1, 0, 0, 0, \ldots  \right)  \) cannot be reached via \( S \).
    </div>
</div>
<div class="proposition" id="proposition-the-adjoint-of-the-unilateral-shift-is-the-bilateral-shift" >
    <div class="title">The Adjoint of the Unilateral Shift Is the Bilateral Shift</div>
    <div class="content">
        As per title.
    </div>

    <div class="proof">
        https://math.stackexchange.com/questions/1043965/eigenvalue-of-a-unilateral-shift-operator/1044057#1044057
        https://chatgpt.com/share/672160d4-7b14-8007-91cb-a5a8e41d359e
        Just note:
        \[
        \begin{align*}    
            \left\langle S \left( x \right), y  \right\rangle &= \left\langle \left( 0, x_1, x_2, \ldots  \right), \left( y_1, y_2, y_3 , \ldots \right) \right\rangle \\
        &= 
        \end{align*}    
        \] 

        First we take a look at \(  =  \) 
    </div>
</div>
<div class="proposition" id="proposition-the-bilateral-shift-is-unitary" >
    <div class="title">The Bilateral Shift Is Unitary</div>
    <div class="content">
        TODO: Add the content for the proposition here.
    </div>

    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>
<div class="theorem" id="theorem-closed-graph-theorem" >
    <div class="title">Closed Graph Theorem</div>
    <div class="content">
        Let \( X, Y \) be banach spaces and \( T : X \to Y \) a linear operator 
    </div>

    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>
<div class="definition" id="definition-automorphism">
    <div class="title">Automorphism</div>
    <div class="content">
        Let \( F \) be a field, then an automorphism of \( F \) is a bijection from \( F \)  to itself that preserves the operations of addition and multiplication. 
    </div>
</div>
<div class="definition" id="definition-sesquilinear-form">
<div class="title">Sesquilinear Form</div>
<div class="content">
            A sesquilinear form on a vector space \(V\) over a field \(F\) is a map
            \[
            \langle \cdot , \cdot \rangle: V \times V \rightarrow F
            \]
              that is linear in the right argument and almost linear in the left, which is to say:
              <ul>
<li> \( \left\langle v_1, c w_1\right\rangle=c\left\langle v_1, w_1\right\rangle \) </li>
<li> \( \left\langle v_1, w_1+w_2\right\rangle=\left\langle v_1, w_1\right\rangle+\left\langle v_1, w_2\right\rangle \) </li>
<li> \( \left\langle c v_1, w_1\right\rangle=\bar{c}\left\langle v_1, w_1\right\rangle \) </li>
<li> \( \left\langle v_1+v_2, w_1\right\rangle=\left\langle v_1, w_1\right\rangle+\left\langle v_2, w_1\right\rangle
     \) </li>
</ul>
</div>
</div>
<div class="definition" id="definition-adjoint-of-a-sesquilinear-form">
<div class="title">Adjoint of a Sesquilinear Form</div>
<div class="content">
            Given a sesquilinear form, \( \left( \cdot , \cdot  \right)  \) then we define the adjoint form as 
            \[
            \left( x \mid y \right) ^ * = \left( \bar y \mid \bar x \right) 
            \] 
        </div>
</div>
<div class="definition" id="definition-self-adjoint-sesquilinear-form">
<div class="title">Self Adjoint Sesquilinear Form</div>
<div class="content">
            We say that a sesquilinear form is self adjoint diff:
            \[
              \left( x \mid  y \right) = \left( x \mid y \right) ^ *
            \] 
        </div>
</div>
<div class="definition" id="definition-hilbert-space">
<div class="title">Hilbert Space</div>
<div class="content">
          A hilbert space is a real or complex <a class="knowledge-link" href="/algebra/linear/vector_spaces/linear_transformations.html#definition-inner-product-space">inner product space</a> that is also a complete metric space with respect to the norm \( \lVert x \rVert = \sqrt{\langle x, x \rangle}  \). In other words the vector space under discussion is a <a class="knowledge-link" href="/analysis/linear_operators.html#definition-banach-space">Banach space</a>.
        </div>
</div>
<div class="definition" id="definition-self-adjoint-matrix" >
    <div class="title">Self Adjoint Matrix</div>
    <div class="content">
        A synonym for <a class="knowledge-link" href="/algebra/linear/matrices.html#definition-hermitian-matrix">hermitian</a>.
    </div>
</div>
<div class="definition" id="definition-convex-set">
<div class="title">Convex Set</div>
<div class="content">
            A convex set is a subset \( C \) of a vector space such that for any two points \( x, y \in C \), the line segment connecting \( x \) and \( y \) is entirely contained within \( C \). Formally, for all \( \lambda \in [0, 1] \), the point 
          \[ 
          \lambda x + (1 - \lambda) y \in C 
          \].
        </div>
</div>
<div class="lemma" id="lemma-a-convex-subset-of-a-hilbert-space-has-a-unique-closest-element-to-a-point-in-the-hilbert-space">
<div class="title">A Convex Subset of a Hilbert Space Has a Unique Closest Element to a Point in the Hilbert Space</div>
<div class="content">
          If \( C \) is a closed, nonempty, convex subset of a hilbert space \( H \), then for every \( y \in H \) there is a unique \( x \in C \) that minimizes the distance from \( y \) to \( C \) 
        </div>
<div class="proof">
            Let \( C \) be a subset as specified above, and let \( y \in H \), finding the closest point in \( C \) to \( y \) is equivalent to finding the closest point in \( D = C - y \) to \( 0 \), which is simpler to solve, so we prove this equivalent statement. Now set \( p = \inf \left( \left\{ \lVert x \rVert : x \in D \right\}  \right)  \), , and note from the parallelogram law we have that for any \( x, y \in D \) 
          \[
            \lVert x - y \rVert  ^  2 = 2 \left( \lVert x \rVert ^ 2 + \lVert y \rVert ^  2   \right)  - \lVert x + y  \rVert ^ 2
          \] 
          Note that <a class="knowledge-link" href="/analysis/linear_operators.html#definition-convex-set">since</a> \( \frac{ 1 }{ 2 } x + \frac{ 1 }{ 2 } y \in D  \) then we know that \( \lVert \frac{ 1 }{ 2 } x + \frac{ 1 }{ 2 } y \rVert \ge p \) so that \( \lVert x + y \rVert \ge 2 p  \) in otherwords from the previous equality we obtain 
          \[
          \lVert x - y \rVert ^ 2 \le 2 \left( \lVert x \rVert ^ 2 + \lVert y \rVert ^  2   \right) - 4p ^2
          \] 
          Now as \( p \) is the infimum ,then we can find a sequence \( \left( x _ n \right) : \mathbb{ N } _1 \to D  \) such that \( \lVert x _ n \rVert \to p  \) and more specifically \( \lVert x _n  \rVert ^ 2 \to p ^2  \) , we'll show that \( x _ n \) is <a class="knowledge-link" href="/analysis/single_variable/real_numbers.html#definition-cauchy-sequence">cauchy</a>, to do so let \( \epsilon \in \mathbb{ R } ^ +  \) then since \( \lVert x  _ n \rVert ^ 2 \to p ^ 2  \) then we obtain some \( N ^ \prime  \) such that for any \( k \ge N ^ \prime  \) we have \( \lVert x _ k \rVert \lt p ^ 2 + \epsilon   \), now in our context we take \( N = N ^ \prime  \) and let \( n, m \ge N \) therefore we have that:
          \[
          \lVert x _ n - x _ m  \rVert ^ 2 \le 2 \left( \lVert x _n  \rVert ^ 2 + \lVert y _ m \rVert ^  2   \right) - 4p ^2 \le 2 \left( \left( p ^ 2 + \epsilon  \right) + \left( p ^ 2 + \epsilon  \right)   \right)  - 4p ^ 2 = 4\epsilon 
          \] 
          where we could then say \( \lVert x _ m - x _n \rVert \lt 2 \sqrt{ \epsilon  }   \) therefore \( x _ n  \) is cauchy, and thus \( x _ n \) converges to some point \( y \in H \), but since \( D \) is closed then also \( y \in D \), moreover we know that \( \lVert y \rVert = \lim _ { n \to \infty  } \lVert x _ n \rVert = p    \), thus we've shown that such a smallest element in \( D \) exists. To show it unique, then suppose there were two \( u, v \in D \) that were the smallest, but then revisiting our old inequality we have:
          \[
          \lVert u - v \rVert \le 2 \left( \lVert u \rVert ^ 2 + \lVert v \rVert ^  2   \right) - 4p ^2 = 2 \left( p ^ 2 + p ^  2   \right) - 4p ^2 = 0
          \] 
          so we deduce \( u = v \) 
        </div>
</div>
<div class="definition" id="definition-functional">
<div class="title">Functional</div>
<div class="content">
          Given a <a class="knowledge-link" href="/algebra/linear/vector_spaces/vector_spaces.html#definition-vector-space-over-a-field">vector space</a> \( \left( V, F \right)  \) 
        </div>
</div>
<div class="definition" id="definition-spectrum-of-a-linear-operator" >
  <div class="title">Spectrum of a Linear Operator</div>
  <div class="content">
      \[
            \operatorname{ Spec } \left( T \right) = \left\{ \lambda \in \mathbb{ C } : T - \lambda I \text{ is not invertible } \right\} 
      \] 
  </div>
</div>
<div class="definition" id="definition-co-kernel" >
  <div class="title">Co-kernel</div>
  <div class="content">
      The co-kernel of a linear opertor \( T : V \to V\) is 
    \[
      \operatorname{ coker } \left( T \right) = V \setminus \operatorname{ im } \left( T \right) 
    \] 
  </div>
</div>
<div class="definition" id="definition-fredholm-operator" >
    <div class="title">Fredholm Operator</div>
    <div class="content">
        We say that a linear operator \( T : X \to Y \) is <b>fredholm</b> when \( \operatorname{ dim }  \left( \operatorname{ ker } \left( T \right)   \right) \lt \infty  \) and \( \operatorname{ dim } \left( Y \setminus \operatorname{ im } \left( T \right)  \right) \lt \infty  \) 
    </div>
</div>
<div class="definition" id="definition-finite-rank-linear-operator" >
    <div class="title">Finite Rank Linear Operator</div>
    <div class="content">
      A linear operator \( T \) on a hilbert space \( H \) has finite rank if \( T \left( H \right)  \) is a finite dimensional subspace of \( H \) 
    </div>
</div>
<p>
    When you look at the spectrum of a finite rank operator their spectrum is always discrete and is only the eigen values that they have.
</p>
<div class="proposition" id="proposition-compact-operators-are-limits-of-finite-rank-operators" >
    <div class="title">Compact Operators Are Limits of Finite Rank Operators</div>
    <div class="content">
        TODO: Add the content for the proposition here.
    </div>
    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>
<p>
    This means that the eigenvalues form a sequence that converges to 0, and this is what the spectrum of a finite rank operator looks like. If we have a compact self adjoint linear operator then we know that the eigenvalues all sit on \( \mathbb{ R }  \) 
</p>
<div class="theorem" id="theorem-spectral-theorem-for-compact-operators" >
    <div class="title">Spectral Theorem for Compact Operators</div>
    <div class="content">
        Suppose that \( T \) is compact and self-adjoint operator on a seprable hilbert space \( H \) , then there is a sequence \( \left( \lambda _ n \right) _ { \mathbb{ N } _ 1 }  \) of eigenvalues of \( T \) and an orthanormal basis \( \left( b _ n \right) _ { \mathbb{ N } _ 1 }  \) of \( H \) such that \( \lambda  _ n \to 0 \) and \( T b _ n = \lambda _ n b _ n \) 
    </div>
    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>
<div class="definition" id="definition-self-adjoint-linear-operator" >
    <div class="title">Self Adjoint Linear Operator</div>
    <div class="content">
        We say that \( T = T ^ * \) which means for all \( x, y \in H \) 
      \[
          \langle Tx, y \rangle = \langle x, Ty \rangle
      \] 
    </div>
</div>
<div class="proposition" id="proposition-real-spectrum-iff-self-adjoint" >
    <div class="title">Real Spectrum Iff Self Adjoint</div>
    <div class="content">
      \( \operatorname{ Spec } \left( T \right) \subseteq \mathbb{ R }    \) iff \( T \) is self-adjoint
    </div>
    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>
<div class="definition" id="definition-positive-linear-operator" >
    <div class="title">Positive Linear Operator</div>
    <div class="content">
        \( \operatorname{ Spec } \left( T \right) \subseteq [0, \infty )  \) and we say that \( T \ge 0 \) 
    </div>
</div>
<div class="definition" id="definition-the-square-root-of-a-linear-operator-exists-if-it-is-positive" >
    <div class="title">The Square Root of a Linear Operator Exists If It Is Positive</div>
    <div class="content">
        proof diagonizliz T, and define \( \sqrt{ T }  \) as \( \sqrt{ T } b _ n = \sqrt{ \lambda _ n } b _ n  \), show that the square roots commute because they square to T, and so you should be able to simulatenuously diagonilize them so the square of the eigens are equal so then the square roots are equal.
    </div>
</div>
<div class="theorem" id="theorem-if-t-is-self-adjoint-then-t-is-bounded" >
    <div class="title">If T Is Self Adjoint Then T Is Bounded</div>
    <div class="content">
        TODO: Add the content for the theorem here. (Hellinger and Topis)
    </div>
    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>
<h1>week 1</h1>
<div class="definition" id="definition-nth-dirichlet-kernel" >
    <div class="title">Nth Dirichlet Kernel</div>
    <div class="content">
        Let  \( T \) be the unit circle and for each \( n \in \mathbb{ Z }  \) let \( \chi _ n : T \to \mathbb{ C }  \) be the function \( \chi _ n \left( x \right) = e ^ { 2 \pi i n x }  \) and for each \( N \in \mathbb{ N } _1 \) let \( D _ N \in C \left( T \right)  \) be the <b>n-th dirichlet kernel</b> defined as 
        \[
          D _ N \left( x \right) = \sum _ { n = -N } ^ N \chi _ n \left( x \right) 
        \] 
    </div>
</div>
<div class="proposition" id="proposition-the-dirichlet-kernel-is-real-valued-and-integrates-to-1" >
    <div class="title">The Dirichlet Kernel Is Real Valued and Integrates to 1</div>
    <div class="content">
        \(D_N\) is real-valued, specifically:
        \[
            D_N(x)=\frac{\sin \left(\left(N+\frac{1}{2}\right) 2 \pi x\right)}{\sin (\pi x)}
        \]
        if \(x \neq 0\), and \(D_N(0)=2 N+1\). Moreover we have that  
        \[
        \int_{\mathbb{T}} D_N(x) d x=1
        \].
    </div>

    <div class="proof">
        When \( x = 0 \) we have that \( e ^ { 2 \pi i n 0 } = 1 \) therefore \( \sum _ { - N } ^ N \chi _n \left( 0 \right) = 2n + 1  \) where the plus one comes from \( n = 0 \), when we have that \( x = 0 \) then we have the following
        \[
        \begin{align*}
            \sum _ { - N } ^ N \chi _ n \left( 0 \right) &= \sum _ { - N } ^ N \left( e ^ { 2 \pi i x } \right) ^ n \\
            &= \sum _ { - N } ^ N \left( e ^ { 2 \pi i x } \right) ^ n \\
            &=  \left( e ^ { 2 \pi i x } \right) ^ { -N } + \ldots + \left( e ^ { 2 \pi i x } \right) ^ { 0 } + \ldots + \left( e ^ { 2 \pi i x } \right) ^ { -N }   \\
            &= e ^ { - 2 \pi i N x } \left( 1 + \ldots + \left( e ^ { 2 \pi i x } \right) ^ { 2 N } \right) 
        \end{align*}
        \] 
        Now recall that 
    </div>
</div>

<div class="lemma" id="lemma-bounded-linear-functional-integral" >
    <div class="title">Bounded Linear Functional Integral</div>
    <div class="content">
        The linear functional \(T_n: C(\mathbb{T}) \rightarrow \mathbb{R}\) defined by
            \[
            T_n f=\int_{\mathbb{T}} f(x) D_n(x) \mathrm{d} x
            \]

            is bounded, with

            \[
            \left\|T_n\right\|=\int_{\mathbb{T}}\left|D_n(x)\right| \mathrm{d} x .
            \]
    </div>
    <div class="proof">

    </div>
</div>

Lemma 4.7. 


<div class="theorem" id="theorem-embryionic-spectral-theorem" >
    <div class="title">Embryionic Spectral Theorem</div>
    <div class="content">
        For any \( p \in \mathbb{ R } \left[ x \right]  \) and \( T \) which is adjoint and positive then if we know that for all \( t \in [ - \lVert T \rVert, \lVert T \rVert   \) we have
        \[
            \lVert p \left( T \right)  \rVert \le \lVert p \left( t \right)  \rVert 
        \] 
    </div>
    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>
<div class="definition" id="definition-l2-space" >
    <div class="title">L2 Space</div>
    <div class="content">
        An \( L ^ 2 \) space constists of square integrable functions so that \( L ^ 2 \) is the collection of functions such that 
        \[
          \int \left\lvert f \left( x \right)  \right\rvert ^ 2 dx \lt \infty 
        \] 
    </div>
</div>
<div class="definition" id="definition-multiplication-operator" >
    <div class="title">Multiplication Operator</div>
    <div class="content">
        Suppose that \( f \in L ^ 2 \) then we define the multiplication operator for \( f \) as \( M _ f : L ^ 2 \to L ^ 2 \) such that 
        \[
            M _ f \left( g \right) = f g
        \] 
    </div>
</div>
<div class="definition" id="definition-trace-class-linear-operator" >
    <div class="title">Trace-class Linear Operator</div>
    <div class="content">
        Let \(\mathcal{H}\) be a Hilbert space. A linear operator \(A: \mathcal{H} \rightarrow \mathcal{H}\) is called trace-class if its trace-class norm
        \[
        \|A\|_{\mathrm{tc}}=\sup _{\left(v_n\right),\left(w_n\right)} \sum_{n=1}^N\left|\left\langle A v_n, w_n\right\rangle\right|
        \]
        is finite, where the supremum is taken over all integers \(N \geqslant 0\) and over any two finite lists of orthonormal vectors \(\left(v_1, \ldots, v_N\right)\) and \(\left(w_1, \ldots, w_N\right)\) of the same length \(N\).
    </div>
</div>
<h1>Algebra</h1>



(1.13). Definition (unitisation). 
<p>
    Consider \( \ell ^ \infty \left( X \right)  \) (the collection of bounded functions from \( S \) into \( C \)   with the sup norm, then it is a banach algebra, also it is unital with the constant 1 function, and moreover is commutative
</p>
<p>
    \( C _ b \left( X \right)  \) where \( X \) is a non-empty topological space with the sup norm is a banach algebra also it is unital with the constant 1 function, and moreover is commutative
</p>
<p>
    \( C _ 0 \left( X \right)  \) the functions which vanish at infinity, where \( X \) is a locally compact hausdorff space is also a banach algebra
</p>
<p>
    in a measure space, then \( L ^ \omega \left( X, \mu \right)  \) the measure space is also a banach algebra
</p>
<p>
    A = disk algebra, \( \left\{ f \in C \left( \bar D \right) : f \text{ is holo on } \operatorname{ int } \left( D \right)   \right\}  \) where \( D \) is the unit disk in \( \mathbb{ C }  \) is not a banach algebra. Note that this is not a \( C ^ * \) algebra
</p>
<p>
    \( X \) is a NVS and \( Y \) a baanch space, then \( B \left( X, Y \right)  \) the bounded functions? is a banach algebra
</p>
<p>
    \( M _ n \left( \mathbb{ C }  \right)  \) the matrix algebras (n x n matrices with values in C), are banach algebras
</p>
<p>
    \( M _ n \left( A  \right)  \) is a banach algebra whenever \( A \) is.
</p>
<h1>Now a bunc of facts from tutotirla</h1>
<p>
    If \( A \) is a banach algebra and \( I \) is a proper ideal in \( A \) then \( \bar I \) is also a proper ideal in \( A \) implies that maximal ideals are closed.
</p>
<p>
    I is a closed ideal in A implies A / Iis a banach algebra
</p>
<p>
    Given a homomorphism \( \phi : A \to B \) then \( \operatorname{ ker } \left( \phi  \right)   \) is a closed ideal and \( \phi  \) is unitl if \( \phi \left( 1 _ A \right) = 1 _ B  \) 
</p>
<p>
    Suppose that \( A \) is unital, and \( p \left( z \right) \in \mathbb{ C } \left[ x \right]   \) then given any \( a \in A \) we can construct a map \( \operatorname{ ev } _ a : \mathbb{ C } \left[ z \right] \to A   \) via \( p \left( z \right) = p\left( a \right)   \) is an algebra homomorphism.
</p>
<p>
    Def: \( a \in A \) , then \( \operatorname{ sp } \left( a \right) = \left\{ \lambda \in \mathcal{ C } : a - \lambda \notin \operatorname{ GL } \left( A \right)    \right\}    \) is closed, and you can show that \( \lambda \in \operatorname{ sp } \left( a \right)   \) then \( \lVert \lambda  \rVert \le \lVert a \rVert   \) 
</p>
<p>
    If \( A \) is a banach algebra, then we do Unitization, making \( A ^ \prime  = A \circplus \mathcal{ C }  \) as a vector space, if you define multiplication component wise it turns out not to be unital, but instead if you do \( \left( a, \lambda  \right) \cdot \left( b, \mu \right) = \left( ab + \lambda b + \mu a, \lambda \mu \right)    \) this multiplication makes \( A ^ ' \) into a uanital algebra with unit \( \left( 0, 1 \right)  \) and \( \lVert a + \lambda  \rVert = \max \left( \lVert a \rVert, \left\lvert \lambda  \right\rvert    \right)   \) 
</p>
<div class="definition" id="definition-c-star-algebra" >
    <div class="title">C Star Algebra</div>
    <div class="content">
        A \( C ^ * \) algebra \( \mathcal{ A }  \)  is a <a class="knowledge-link" href="/analysis/linear_operators.html#definition-banach-algebra">banach algebra</a> over the complex numbers, equipped with an involution (the \( * \) operation) satisfying the following properties, first of the algebra:
        <ul>
            <li>\( \mathcal{ A }  \) is a vector space over \( \mathcal{ C }  \)  </li>
            <li>\( a \left( b + c \right) = a b + ac  \) </li>
            <li>\( \left( \lambda a \right) b = \lambda \left( a b \right) \) </li>
        </ul>
        then of the involution, stating that there is a map \( * : \mathcal{ A } \to \mathcal{ A } \) called the involution satisfying
        <ul>
            <li>\( \left( a ^ * \right) ^ * = a  \) </li> 
            <li>\( \left( a + b \right) ^ * = a ^ * + b ^ *   \) </li> 
            <li>\( \left( \lambda a \right) ^* = \bar \lambda a ^ * \) </li> 
            <li>\( \left( a b \right) ^ * = b ^ * a ^ *  \) </li> 
        </ul>
        Interaction with the norm
        <ul>
            <li>\( \lVert a * a \rVert = \lVert a \rVert ^ 2 \) </li>
        </ul>
    </div>
</div>
<div class="theorem" id="theorem-open-mapping-theorem" >
    <div class="title">Open Mapping Theorem</div>
    <div class="content">
        Let \( B _ 1, B _ 2 \) be two <a class="knowledge-link" href="/analysis/linear_operators.html#definition-banach-space">banach space</a> and let \( T \in \mathcal{ B } \left( B_1, B_2 \right)   \) be a surjective linear operator, then \( T \) is a <a class="knowledge-link" href="/topology/quotient_topology.html#definition-open-map">open map</a>
    </div>

    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>
<div class="proposition" id="proposition-fredholm-operators-plus-finite-rank-operators-are-fredholm-operators" >
    <div class="title">Fredholm Operators Plus Finite Rank Operators Are Fredholm Operators</div>
    <div class="content">
        \[
          \operatorname{ Fred } \left( V \right) + \operatorname{ FinRan } \left( V \right) = \operatorname{ Fred } \left( V \right)
        \] 
    </div>

    <div class="proof">
        <p>
            First step is to reduce to the special case of \( \operatorname{ index } \left( T \right) = 0   \) so that the dimension of the kernel and kernel have the same dimension and thus are isomorphic so there is a bijective funciton between them.
        </p>
        <p>
            So now we reduce to the case where \( T \) is invertible,
        </p>
    </div>
</div>
<div class="proposition" id="proposition-the-product-of-linear-operators-with-index-still-has-index" >
    <div class="title">The Product of Linear Operators With Index Still Has Index</div>
    <div class="content">
        TODO: Add the content for the proposition here.
    </div>

    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>

<h1>Spectral Theorem for Normal Operators</h1>

https://personal.math.ubc.ca/~feldman/m511/spectralReview.pdf
https://math.dartmouth.edu/~dana/bookspapers/ln-spec-thm.pdf




<div class="lemma" id="lemma-a-bounded-linear-operator-has-non-empty-spectrum" >
    <div class="title">A Bounded  Linear Operator Has Non-empty Spectrum</div>
    <div class="content">
        Let \(B\) be a Banach space over \(\mathbb{C}\) and \( T \) a bounded linear operator on \( B \) the spectrum \( \operatorname{ sp } (T)\) of \(T\) is non-empty.
    </div>

    <div class="proof">
        TODO: Add the proof here.
    </div>
</div>

<div class="lemma" id="lemma-an-eigenvalue-for-a-normal-linear-operator-is-an-eigenvalue-for-the-adjoint-when-taking-the-conjugate" >
    <div class="title">An Eigenvalue for a Normal Linear Operator Is an Eigenvalue for the Adjoint When Taking the Conjugate</div>
    <div class="content">
        If \( T \in B \left( \mathcal{ H }  \right)  \) is normal, and if \( \lambda , v \) is an eigen value vector pair, then \( v \) is an eigen vector for \( T ^ * \) with eigen value \( \bar \lambda  \) 
    </div>

    <div class="proof">
        Consider the eigenspace of \( \lambda  \), that is  \(\mathcal{E}_\lambda=\{v \in \mathcal{H}: T v=\lambda v\}\). Since \( T \) is normal then we have:  \(T T^* v=T^* T v=\lambda T^* v\), which shows that \(T^* v \in \mathcal{E}_\lambda\). If \(w \in \mathcal{E}_\lambda\), then

        \[
        \begin{align*}
            \left(T^* v-\bar{\lambda} v, w\right) & =\left(T^* v, w\right)-\bar{\lambda}(v, w) \\
            & =(v, T w)-\bar{\lambda}(v, w) \\
            & =0
        \end{align*}
        \]


        Since \(T^* v-\bar{\lambda} v \in \mathcal{E}_\lambda\), we have \(T^* v=\bar{\lambda} v\).
    </div>
</div>



<h2>spectral theory of banach algebras</h2>


embryionic spectral theorem for any p in R[x] and T = T* (adjoint) >= 0, 

then || p (T) || <= sup |t| <= ||T| of |p(t)|

recall that the linear operators with the operator norm is a complete space
proof pn(T) is cauchy because 

pn - pm is small
pn(T) - pm(T)  is small so that is cauchy so the limit exists

define f(T), f in C_r([-||T||, ||T||])


      adding definition of dense and then proof in 2.1







      in a hilbert space if you have a closed subspace then it always has a complementary subspace
      equilvalenlty thereis an orthoganal complement

      in linear algebra a a complementary subspace is one that is orgnaogonzl one and the union is the entire space, that's one of the the fundamental theorems in hilbert space theory

      any closed convex set in a hilbert space, and a point which is not in the space, then there is a unique closest point in the convex set to the point. (prove this one)

      if you have two inner products on a vector space and they turn them into a hilbert space and if they hav

      the given a hilbertspace then the number of elements in a ahilbert space basis is unique, so we prove that the number for here is the same as the number fo rhere, so the way you do it is that the humbe rof elements in a basis ais the same number of elements in a dense subset of the hilbert space, and you look at the smallest cardinal number in thedencse set and that's tthe number of elements in the basis, and so once you have the two orthanomral basis for the two bases

      given a hilbert space H and a bounded operators T = T* in B(H) bounded operator, polynomials are functions in the operator too, and there's something mysterious about them in the first instance, you have a varaible x in the first but then you can plug in an operator to a polynomial, so suppose that p in C[x] (complex coeffiecients), suppose that ||T|| &lt;= 1, then what you do is that you say that ||p(t)|| &lt;= eps for t in [-1, 1], then if we change t to T then we also know that ||p(T)|| &lt;= eps (that's the spectral theorem, because once you know it's its fairly clear sailing)


      the tutorial

      suppose we have some field k and a vector space over k

      C* (* is an ivoluation) an algebra is a ring with addition, multiplication, and a norm

      gelfands theorem : If A is a commutative unital C*-algebra, then A =~ C(X) = {f: X -&gt; C: f cts} for some compact hausdorff X.

      C0(R) = {f : R -&gt; C : f cts and lim(fx) x -&gt; oo = lim x -&gt; -oo f(x) = 0 }

      modules are like vector spaces, and modules/k are precicely vector spaces / k, but modules don't always have a basis, but recall that a basis would be a subset B of M st B is lin indep (in a module this means given m1, m2 in B, then the solution to the equation r1m1 + r2m2 = 0 the same way we do in vector spaces), and forall m in M, we can find finitely many elements such that it is a linear comb of them.

      given a banach space over C, then the dimension is not aleph 0

      consider l^oo (N) = {(x1, x2, ...) that are bounded}, the a basis could be e1, e2, ... and we would guess this is a basis for l^oo, but the problem is that we have an infinite sum, and so we need an infinite sum to exists and htus need converergence but we don't have a norm.

      so we have another idea which is the shauder basis, the {e_i}'s form a shauder basis for l^w, but this depends on the norm in the space,  given a banach space over C it has an uncountable hamel basis.

      Exercise produce the dimension of X over C in a caoniacal way

      a banach space is a hilbert space iff the inner product satisfies the paralellogram law.

      From any ellipse you get an inner product, suppose it has major axis a and minor axis b then the inner product is given by ||(x, y)||^2 = (x/a)^2 + (y/b)^2 then the equation is given by 

      &lt;., .&gt;: VxV -&gt; R: symmetric biliear forms, is degenerate iff for every x, there is a y such that <x, y=""> &gt;0 
        Thm Riesz lemma ||&lt;*, x&gt;||_H* = ||x||_H

      add the 




https://www.math.mcgill.ca/jakobson/courses/ma667/mendelsontomberg-spectral.pdf
https://www.math.uwo.ca/faculty/khalkhali/files/Fredholm.pdf
https://math.stackexchange.com/questions/282140/the-inclusion-relation-sigmaab-subseteq-sigmaa-sigmab-is-not-true
https://mathoverflow.net/questions/14246/spectra-of-sums-and-products-in-banach-algebras-was-spectrum-in-banach-algeb
https://math.stackexchange.com/questions/4668576/infinity-norm-and-operator-norm-question
https://www.math.ucdavis.edu/~anne/WQ2007/mat67-Ll-Spectral_Theorem.pdf
https://math.libretexts.org/Bookshelves/Linear_Algebra/Book%3A_Linear_Algebra_(Schilling_Nachtergaele_and_Lankham)/11%3A_The_Spectral_Theorem_for_normal_linear_maps/11.01%3A_Self-adjoint_or_hermitian_operators
http://www.math.ucdavis.edu/~anne/linear_algebra/mat67_course_notes.pdf
https://ocw.mit.edu/courses/18-102-introduction-to-functional-analysis-spring-2021/8fb8d5c170f1613151aca71de21027bc_MIT18_102s21_full_lec.pdf
https://math.libretexts.org/Bookshelves/Linear_Algebra/Book%3A_Linear_Algebra_(Schilling_Nachtergaele_and_Lankham)/11%3A_The_Spectral_Theorem_for_normal_linear_maps/11.01%3A_Self-adjoint_or_hermitian_operators
http://pfister.ee.duke.edu/courses/ecen601/notes_ch5.pdf
https://math.stackexchange.com/questions/4050748/reference-for-wold-decomposition-theorem-operator-theory
https://en.wikipedia.org/wiki/Direct_sum
https://en.wikipedia.org/wiki/Orthogonal_complement
https://arxiv.org/pdf/math/0701306#theorem.2.14.12

    use this one for essay:
https://tqft.net/web/teaching/current/Analysis3/LectureNotes/03.Compact.operators.pdf
https://www.math.ucdavis.edu/~anne/WQ2007/mat67-Ll-Spectral_Theorem.pdf
